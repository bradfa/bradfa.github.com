---
layout: post
title: Base16 Speed
date: 2013-06-04
comments: false
---

Base16 conversion from printable characters to binary data, and back again, is
important for one project I work on.  Doing conversion as fast as possible is a
good thing.

I had some code that did the binary to printable characters conversion well
enough, using `sprintf()`, but I thought it wasn't optimal, so I decided to find
out.

I wrote some quick and dirty code, in my [github][github], to test the
performance difference between using `sprintf()` and using a lookup table.
Turns out, the LUT is about 10 times faster on my Core-i7 and about 14 times
faster on a BeagleBone.  That's quite an improvement!

I'm sure there's an even faster way to do other things my code does less than
optimally, now I'm on the hunt!

BeagleBone run:

```
root@localhost:~# ./test test.file 
Read 14659584 bytes
sprintf bin to hex took 20850000 clocks
bintohlut bin to hex took 1470000 clocks
htob hex to bin took 10860000 clocks
```

Intel Core-i7 run:

```
andrew@brick:~/git/base16test$ ./test /dev/urandom 
Read 33554432 bytes
sprintf bin to hex took 2750000 clocks
bintohlut bin to hex took 260000 clocks
htob hex to bin took 1080000 clocks
```

[github]:https://github.com/bradfa/base16test
